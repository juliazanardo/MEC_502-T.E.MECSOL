{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 13 (2) - Hamiltonian & Lagrangian Neural Networks\n",
    "### Task\n",
    "Implement and train a Lagrangian neural network\n",
    "- Implement the cost computation in the training loop\n",
    "- Perform a training with the Lagrangian neural network and compare it to the conventional neural network (exercise13_3.ipynb) and the Hamiltonian neural network (`exercise13_1.ipynb`)\n",
    "\n",
    "### Learning goals\n",
    "- Familiarize yourself with Hamiltonian dynamics and neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import grad\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sampling parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx0dt = 1\n",
    "k = 10\n",
    "m = 1\n",
    "\n",
    "tmaxTraining = 1.5\n",
    "numberOfTrainingSamples = 50\n",
    "tmaxValidation = 9\n",
    "numberOfValidationSamples = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**neural network architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 50\n",
    "layers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "epochs = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize, neurons, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = layers\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(inputSize, neurons)\n",
    "        self.linear2 = torch.nn.ModuleList()\n",
    "        for i in range(self.layers):\n",
    "            self.linear2.append(torch.nn.Linear(neurons, neurons))\n",
    "        self.linear3 = torch.nn.Linear(neurons, outputSize)\n",
    "        self.activation = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.activation(self.linear1(x))\n",
    "        for i in range(self.layers):\n",
    "            y = self.activation(self.linear2[i](y))\n",
    "        y = self.linear3(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**derivative function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDerivative(y, x, n):\n",
    "    \"\"\"Compute the nth order derivative of y = f(x) with respect to x.\"\"\"\n",
    "\n",
    "    if n == 0:\n",
    "        return y\n",
    "    else:\n",
    "        dy_dx = grad(y, x, torch.ones_like(y), create_graph=True, retain_graph=True)[0]\n",
    "        return getDerivative(dy_dx, x, n - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**analytical solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = np.sqrt(k / m)\n",
    "\n",
    "A = dx0dt / omega\n",
    "phi = 0\n",
    "x = lambda t: A * np.sin(omega * t + phi)\n",
    "dxdt = lambda t: omega * A * np.cos(omega * t + phi)\n",
    "ddxdtt = lambda t: - omega ** 2 * A * np.sin(omega * t + phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tTraining = np.linspace(0, tmaxTraining, numberOfTrainingSamples)\n",
    "# TODO add noise\n",
    "trainingData = torch.vstack((torch.from_numpy(x(tTraining)),\n",
    "                             torch.from_numpy(dxdt(tTraining)),\n",
    "                             torch.from_numpy(ddxdtt(tTraining)))).to(torch.float32).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tValidation = np.linspace(0, tmaxValidation, numberOfValidationSamples)\n",
    "validationData = torch.vstack((torch.from_numpy(x(tValidation)),\n",
    "                               torch.from_numpy(dxdt(tValidation)),\n",
    "                               torch.from_numpy(ddxdtt(tValidation)))).to(torch.float32).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelInputTraining = trainingData[:, :2]\n",
    "modelInputTraining.requires_grad = True\n",
    "\n",
    "modelInputValidation = validationData[:, :2]\n",
    "modelInputValidation.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamiltonian model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNN(2, 1, neurons, layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "costHistory = np.zeros(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    LPred = model(modelInputTraining)\n",
    "\n",
    "    # your code goes here: compute the cost function\n",
    "    \n",
    "    costHistory[epoch] = cost.detach()\n",
    "\n",
    "    cost.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"Epoch: {}/{}\\t\\tCost function: {:.3E}\".format(epoch, epochs, cost.detach()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfTimeSteps = 10000  # for the forward Euler scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**forward Euler scheme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tPrediction = np.linspace(0, tmaxValidation, numberOfTimeSteps + 1)\n",
    "dt = tmaxValidation / numberOfTimeSteps\n",
    "xPrediction = torch.zeros((2, numberOfTimeSteps + 1), requires_grad=False)\n",
    "xPrediction[:, 0] = validationData[0, :2]\n",
    "\n",
    "LPredictions = np.zeros(numberOfTimeSteps)\n",
    "LLabel = 0.5 * m * validationData[:, 1] ** 2 - 0.5 * k * validationData[:, 0] ** 2\n",
    "\n",
    "for i in range(numberOfTimeSteps):\n",
    "    currentx = xPrediction[:, i].unsqueeze(0).detach()\n",
    "    currentx.requires_grad = True\n",
    "    LPred = model(currentx)\n",
    "    LPredictions[i] = LPred[0].detach()\n",
    "\n",
    "    dLPreddx = getDerivative(LPred, currentx, 1)\n",
    "    Hessian = getDerivative(dLPreddx[:, 0], currentx, 1)[:, 1]\n",
    "    ddxttPred = (1. / dLPreddx[:, 1]) * (dLPreddx[:, 0] - Hessian * currentx[:, 1])\n",
    "\n",
    "    xPrediction[:, i + 1] = (xPrediction[:, i] + dt * torch.tensor([currentx[0, 1], ddxttPred[0]])).detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**transient response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(tPrediction, xPrediction[0, :], 'k')\n",
    "ax.plot(tValidation, validationData[:, 0], 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**position-momentum space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(xPrediction[0, :], xPrediction[1, :], 'k')\n",
    "ax.plot(validationData[:, 0], validationData[:, 1], 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**energy evolution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(tPrediction, 0.5 / m * xPrediction[1, :] ** 2, 'k--')\n",
    "ax.plot(tPrediction, 0.5 * k * xPrediction[0, :] ** 2, 'k:')\n",
    "ax.plot(tPrediction, 0.5 / m * xPrediction[1, :] ** 2 + 0.5 * k * xPrediction[0, :] ** 2, 'k')\n",
    "\n",
    "ax.plot(tValidation, 0.5 / m * validationData[:, 1] ** 2, 'r--')\n",
    "ax.plot(tValidation, 0.5 * k * validationData[:, 0] ** 2, 'r:')\n",
    "ax.plot(tValidation, 0.5 / m * validationData[:, 1] ** 2 + 0.5 * k * validationData[:, 0] ** 2, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lagrangian prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(tPrediction[:-1], LPredictions, 'k')\n",
    "ax.plot(tValidation, LLabel, 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**learning history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(costHistory, 'k')\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
